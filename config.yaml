# GRAG项目配置文件

# LLM模型配置
llm:
  # 模型提供商和名称
  provider: "ollama"  # 可选: "ollama", "openai", "azure_openai", "bedrock", "huggingface"
  model_name: "qwen2.5:7b-instruct-fp16"
  host: "http://localhost:11434"
  options:
    num_ctx: 32768

# 文档处理配置
document:
  input_dir: "./data"  # 文档存放目录
  output_graph_path: "./result/grag_data1/graph.json"  # 输出图结构路径
  # 文档分块设置
  chunk_size: 1000
  chunk_overlap: 200
  # 实体提取设置
  max_gleaning: 2  # 实体关系提取的最大迭代次数

#剪枝和分类器开启
classifier:
  enable: true
prune:
  enable: true

# 嵌入模型配置
embedding:
  # 嵌入模型提供商和名称
  provider: "ollama"  # 可选: "ollama", "openai", "azure_openai", "bedrock", "huggingface"
  model_name: "bge-m3"
  host: "http://localhost:11434"
  embedding_dim: 1024
  max_token_size: 8192
  batch_size: 32

# 存储配置
storage:
  working_dir: "./result/grag_data1"
  embedding_batch_num: 32

# 查询配置
query:
  # 检索模式
  default_mode: "hybrid"  # 可选: "local", "global", "hybrid", "naive"
  top_k: 60
  max_token_for_text_unit: 4000
  max_token_for_global_context: 4000
  max_token_for_local_context: 4000
  cosine_better_than_threshold: 0.2

# 缓存配置
cache:
  seed: 42
  capacity: 1000

# 模型特定配置
model_specific:
  # OpenAI嵌入模型
  openai_embedding:
    model_name: "text-embedding-3-small"
    embedding_dim: 1536
    max_token_size: 8192
  
  # Azure OpenAI嵌入模型
  azure_openai_embedding:
    model_name: "text-embedding-3-small"
    embedding_dim: 1536
    max_token_size: 8192
  
  # Bedrock嵌入模型
  bedrock_embedding:
    model_name: "amazon.titan-embed-text-v2:0"
    embedding_dim: 1536
    max_token_size: 8192
  
  # Ollama嵌入模型
  ollama_embedding:
    model_name: "bge-m3"  # 与embedding部分保持一致
    embedding_dim: 1024  # 与embedding部分保持一致
    max_token_size: 8192
  
  # Hugging Face嵌入模型
  huggingface_embedding:
    max_token_size: 512

query_classifier:
  model_path: "./result/grag_data1/models/query_classifier.pkl"  # 模型保存路径
  train_data_path: "./train_data/default_query_samples.json"     # 训练数据路径
  batch_size: 16
  epochs: 200
  continual_learning: true  # 如果你希望它支持持续学习逻辑